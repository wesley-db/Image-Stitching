{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wesley-db/Image-Stitching/blob/main/Image_Stitching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob"
      ],
      "metadata": {
        "id": "Cee3vAcLrOs0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "**WARNING: Colab deletes all files everytime runtime is disconnected. Make sure to re-download the inputs when it happens.**"
      ],
      "metadata": {
        "id": "_EOoxrZurmYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Data -- run this cell only one time per runtime\n",
        "!gdown 1fnD0hJ8-_Rngsc-m96ghKtdZAMf0VTjy\n",
        "!unzip \"/content/hill.zip\" -d \"/content/hill\"\n",
        "\n",
        "!gdown 1v2BFVMV0McuD5BstLvDmo1U9MrFAByS5\n",
        "!unzip \"/content/tv.zip\" -d \"/content/tv\"\n"
      ],
      "metadata": {
        "id": "Tspp6CyMroUC",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "YlVZP1tvMAxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Given Helper Functions\n",
        "def est_homography(src, dest):\n",
        "    N = src.shape[0]\n",
        "    if N != dest.shape[0]:\n",
        "        raise ValueError(\"src and diff should have the same dimension\")\n",
        "    src_h = np.hstack((src, np.ones((N, 1))))\n",
        "    A = np.array([np.block([[src_h[n], np.zeros(3), -dest[n, 0] * src_h[n]],\n",
        "                            [np.zeros(3), src_h[n], -dest[n, 1] * src_h[n]]])\n",
        "                  for n in range(N)]).reshape(2 * N, 9)\n",
        "    [_, _, V] = np.linalg.svd(A)\n",
        "    return V.T[:, 8].reshape(3, 3)\n",
        "\n",
        "def apply_homography(H, src):\n",
        "    src_h = np.hstack((src, np.ones((src.shape[0], 1))))\n",
        "    dest =  src_h @ H.T\n",
        "    return (dest / dest[:,[2]])[:,0:2]"
      ],
      "metadata": {
        "id": "y9gRD27_MCDo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############ MY HELPER FUNCTION I - HOMOGRAPHY ##############\n",
        "def find_homography_ransac(src, dest, threshold=0.35, max_iterations=1100):\n",
        "  \"\"\"\n",
        "  Run RANSAC to estimate H.\n",
        "  Input:\n",
        "  - src, dest: coordinates\n",
        "  - threshold: threshold for RANSAC\n",
        "  - max_iterations: number of iterations for RANSAC\n",
        "  Output:\n",
        "  - estimated homography H\n",
        "  - inliers\n",
        "  \"\"\"\n",
        "  ind = np.random.choice(src.shape[0], size=4, replace=False)\n",
        "  best_H = est_homography(src[ind], dest[ind])\n",
        "  best_inliers = get_H_inliers(src[ind], dest[ind], best_H, threshold)\n",
        "  inliers_num = best_inliers.shape[0]\n",
        "\n",
        "  for i in range(max_iterations):\n",
        "    ind = np.random.choice(src.shape[0], size=4, replace=False)\n",
        "    H = est_homography(src[ind], dest[ind])\n",
        "    inliers = get_H_inliers(src[ind], dest[ind], H, threshold)\n",
        "    if inliers.shape[0] > inliers_num:\n",
        "      best_H = H\n",
        "      best_inliers = inliers\n",
        "      inliers_num = inliers.size\n",
        "\n",
        "  return best_H, best_inliers\n",
        "\n",
        "def get_H_inliers(pts1, pts2, H, thresh):\n",
        "  \"\"\"\n",
        "  Computing the indexes of the inliers\n",
        "  Inputs:\n",
        "  - pts1: This is the 'true' coordinates\n",
        "  - pts2: This is the coordinates, which H would be applied at.\n",
        "  - thresh: threshold of the difference\n",
        "  - H: the homography that relates pts2 with pts1\n",
        "  Output:\n",
        "  - The indexes of the inliers\n",
        "  \"\"\"\n",
        "  #Applying homography\n",
        "  est_pts = apply_homography(H,pts1)\n",
        "\n",
        "  #Calculating L2 distance between pts1 and est_pts\n",
        "  x_diff2 = np.square(pts2[::,0] - est_pts[::,0])\n",
        "  y_diff2 = np.square(pts2[::,1] - est_pts[::,1])\n",
        "  delta = np.sqrt(x_diff2 + y_diff2)\n",
        "\n",
        "  return np.where(delta < thresh)[0]\n",
        "\n",
        "def calculate_matches(src, tgt, thresh=0.5):\n",
        "  \"\"\"\n",
        "  The function produces the mask of indexes, where desc1 and desc2 are a good match.\n",
        "  The is a modified code from openCV tutotrial.\n",
        "  Inputs:\n",
        "  - src: the sift feature of the source image\n",
        "  - tgt: the sift feature of the target image\n",
        "  - thresh: threshold for Lowe's ratio test\n",
        "  Output:\n",
        "  - The mask of interest\n",
        "  \"\"\"\n",
        "  #Finding NBB using FLANN\n",
        "  FLANN_INDEX_KDTREE = 0\n",
        "  index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "  search_params = dict(checks=50) # or pass empty dictionary\n",
        "\n",
        "  flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
        "  matches = flann.knnMatch(src,tgt,k=2)\n",
        "\n",
        "  #Conducting Lowe's ratio\n",
        "  nbb1 = np.array([[m.queryIdx,m.trainIdx] for (m,n) in matches])\n",
        "  dist = np.array([[m.distance, n.distance] for (m,n) in matches])\n",
        "  ratio = dist[::,0] < thresh*dist[::,1]\n",
        "  answ = nbb1[np.where(ratio==True)[0]]\n",
        "\n",
        "  return answ[::,0], answ[::,1]"
      ],
      "metadata": {
        "id": "OBO9BLc_-EWG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############ MY HELPER FUNCTION II - CROPING ##############\n",
        "def crop_vertical_darkspots(img, y_warp):\n",
        "  \"\"\"\n",
        "  Crop the vertical dark spots of an image resulting from warping\n",
        "  It's assumed that the right image image is warped to match the left one.\n",
        "  It will throw an error when the warped image is bad (eg.it's flipped after warping)\n",
        "  Input:\n",
        "  - img: the warped image\n",
        "  - y_warp: y-position of all four edges of the right image of the panorama after warping\n",
        "            np.array(top_left(y), top_right(y), bottom_left(y), bottom_right(y))\n",
        " Output:\n",
        "  - The desired image\n",
        "  \"\"\"\n",
        "  y_max = y_warp[2] if y_warp[2] < y_warp[3] else y_warp[3]\n",
        "  if (y_max > img.shape[0]): y_max = img.shape[0]\n",
        "  y_min = y_warp[0] if y_warp[0] > y_warp[1] else y_warp[1]\n",
        "  if (y_min < 0): y_min = 0\n",
        "\n",
        "  if (y_max <= y_min):\n",
        "    raise Exception('The homography matrix is bad. Please try again.')\n",
        "\n",
        "  return img[y_min:y_max, ::, ::]\n",
        "\n",
        "def crop_right_darkspots(img, x_warp):\n",
        "  \"\"\"\n",
        "  Crop the right dark spots of an image resulting from warping\n",
        "  It's assumed that the right image image is warped to match the left one.\n",
        "  It will throw an error when the warped image is bad (eg.it's flipped after warping)\n",
        "  Input:\n",
        "  - img: the warped image\n",
        "  - x_warp: x-position of all four edges of the right image of the panorama after warping\n",
        "                np.array(top_left(x), top_right(x), bottom_left(x), bottom_right(x))\n",
        "  Output:\n",
        "  - The desired image\n",
        "  \"\"\"\n",
        "  x_max = x_warp[1] if x_warp[1] < x_warp[3] else x_warp[3]\n",
        "  if (x_max > img.shape[1]): x_max = img.shape[1]\n",
        "  x_min = x_warp[0] if x_warp[0] > x_warp[2] else x_warp[2]\n",
        "\n",
        "  if (x_max <= 0 or x_max <= x_min):\n",
        "    raise Exception('The homography matrix is bad. Please try again.')\n",
        "\n",
        "  return img[::, :x_max, ::]"
      ],
      "metadata": {
        "id": "8n5zaErJHckj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############ MY HELPER FUNCTION III - SMOOTHING ##############\n",
        "def pyramidsGL(image, num_levels):\n",
        "  '''\n",
        "  Creates Gaussian (G) and Laplacian (L) pyramids of level \"num_levels\" from image im.\n",
        "  G and L are list where G[i], L[i] stores the i-th level of Gaussian and Laplacian pyramid, respectively.\n",
        "  Input:\n",
        "  - image: The source image\n",
        "  - num_levels: The max level of the pyramid\n",
        "  Output:\n",
        "  - The 2 desired pyramids\n",
        "  \"\"\"\n",
        "  '''\n",
        "  G = [image]\n",
        "  image_a = image\n",
        "  for i in range(num_levels-1):\n",
        "    #blur\n",
        "    image_b = cv2.GaussianBlur(image_a,(21,21),0)\n",
        "    #downsample\n",
        "    image_b = cv2.resize(image_b, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_NEAREST)\n",
        "    #adding\n",
        "    G.append(image_b)\n",
        "    #prep for the next\n",
        "    image_a = image_b\n",
        "  ###########################\n",
        "  L = []\n",
        "  for i in range(0,num_levels-1):\n",
        "    image_a = G[i]\n",
        "    #upscale\n",
        "    ds = image_a.shape\n",
        "    image_b = cv2.resize(G[i+1], (ds[1],ds[0]), interpolation=cv2.INTER_NEAREST)\n",
        "    #blur\n",
        "    image_b = cv2.GaussianBlur(image_b,(21,21),0)\n",
        "    #adding\n",
        "    result = image_a - image_b\n",
        "    L.append(result)\n",
        "  L.append(G[num_levels-1])\n",
        "\n",
        "  return G, L\n",
        "\n",
        "def pyramid_blend(L_l, L_r, G_w):\n",
        "  \"\"\"\n",
        "  It performs a pyramid blending on thhe images on the 2 Laplacian pyramids\n",
        "  with G_w as the weight to determine the ratio to blend the two.\n",
        "  Input:\n",
        "  - L_l: The laplacian pyramid of the left image\n",
        "  - L_r: The laplacian pyramid of the right imgae\n",
        "  - G_w: A gaussian pyramid that serves as a weight.\n",
        "  Output:\n",
        "  - A blended image of the left and right images.\n",
        "  \"\"\"\n",
        "  #Blending\n",
        "  blended = []\n",
        "  for l,r,w in zip(L_l,L_r,G_w):\n",
        "    left = l * w\n",
        "    right = r * (1.0 - w)\n",
        "    blended.append( left + right )\n",
        "  #Reconstruction\n",
        "  img = blended[-1]\n",
        "  for i in range(len(blended)-2,-1,-1):\n",
        "    ds_curr = blended[i].shape\n",
        "    img = cv2.resize(img, (ds_curr[1],ds_curr[0]), interpolation=cv2.INTER_NEAREST)\n",
        "    img = cv2.GaussianBlur(img,(21,21),0)\n",
        "    img = blended[i] + img\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "7IxOdr7zMNuX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############ MY HELPER FUNCTION IV - STITCHING ##############\n",
        "def stitch_images(img1, img2):\n",
        "  \"\"\"\n",
        "  Stitch two images at a time.\n",
        "  Inputs:\n",
        "  - img1, img2 with shape [H, W, 3].\n",
        "  Output:\n",
        "  - stitched_image with shape [H, W, 3].\n",
        "  \"\"\"\n",
        "  #1. Detect keypoints\n",
        "  gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
        "  gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "  sift = cv2.SIFT_create()\n",
        "  kp1, des1 = sift.detectAndCompute(gray1,None)\n",
        "  pts1 = cv2.KeyPoint_convert(kp1)\n",
        "  kp2, des2 = sift.detectAndCompute(gray2,None)\n",
        "  pts2 = cv2.KeyPoint_convert(kp2)\n",
        "\n",
        "  #2. Match keypoints\n",
        "  if des1 is None or des2 is None:\n",
        "    raise Exception('No similarities found between the 2 images. Please try again.')\n",
        "  src_mask, tgt_mask = calculate_matches(des1,des2)\n",
        "  pts1_matches = pts1[src_mask]\n",
        "  pts2_matches = pts2[tgt_mask]\n",
        "\n",
        "  #3. Estimate homography with matched keypoints (using RANSAC)\n",
        "  H, inliers = find_homography_ransac(pts1_matches,pts2_matches)\n",
        "\n",
        "  #4. Combine images\n",
        "    #image adjustments\n",
        "  ds1 = img1.shape\n",
        "  ds2 = img2.shape\n",
        "  img_r = cv2.warpPerspective(img2, H, dsize=(ds1[1]+ds2[1],ds1[0]),\\\n",
        "                              flags=cv2.WARP_INVERSE_MAP).astype(np.float64)\n",
        "  edges = np.array([ [0,0],[ds2[1],0],[0,ds2[0]],[ds2[1],ds2[0]] ])\n",
        "  edges_warp = apply_homography(np.linalg.pinv(H), edges)\n",
        "  #edges = np.array(top_left(x,y), top_right(x,y), bottom_left(x,y), bottom_right(x,y))\n",
        "  x_warp, y_warp = edges_warp[::,0].astype(int), edges_warp[::,1].astype(int)\n",
        "  img_r = crop_right_darkspots(img_r, x_warp)\n",
        "\n",
        "  ds_r = img_r.shape\n",
        "  img_l = np.append(img1, np.zeros((ds_r[0],ds_r[1]-ds1[1],3)), 1)\n",
        "\n",
        "    #blend & combine\n",
        "  weight = np.zeros(ds_r)\n",
        "  ovlp_start_x = x_warp[0] if x_warp[0] < x_warp[2] else x_warp[2]\n",
        "  weight[::,:ovlp_start_x+(ds1[1]-ovlp_start_x)//2] = 1\n",
        "\n",
        "  max_level = int( np.floor(np.log2( min(ds_r[0],ds_r[1]) )) )\n",
        "  _, L_r = pyramidsGL(img_r, max_level)\n",
        "  _, L_l = pyramidsGL(img_l, max_level)\n",
        "  G_w,_ = pyramidsGL(weight, max_level)\n",
        "\n",
        "  fin = crop_vertical_darkspots(pyramid_blend(L_l,L_r,G_w), y_warp)\n",
        "\n",
        "  return cv2.convertScaleAbs(fin)"
      ],
      "metadata": {
        "id": "zx78_07RHeyN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Function"
      ],
      "metadata": {
        "id": "kLyTTTL0NVZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/hill'\n",
        "img_list = sorted(glob.glob(os.path.join(img_path, \"*.JPG\"))) \\\n",
        "          + sorted(glob.glob(os.path.join(img_path, \"*.jpg\")))\n",
        "\n",
        "print(img_list)\n",
        "panorama = cv2.imread(img_list[0])\n",
        "panorama = cv2.cvtColor(panorama, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "for i in range(1,len(img_list)):\n",
        "  next_img = cv2.imread(img_list[i])\n",
        "  next_img = cv2.cvtColor(next_img, cv2.COLOR_BGR2RGB)\n",
        "  panorama = stitch_images(panorama, next_img)\n",
        "\n",
        "plt.imshow(panorama)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0sWxf-3WQomQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}