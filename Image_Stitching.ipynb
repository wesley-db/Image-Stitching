{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wesley-db/Image-Stitching/blob/main/Image_Stitching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob"
      ],
      "metadata": {
        "id": "Cee3vAcLrOs0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "**WARNING: Colab deletes all files everytime runtime is disconnected. Make sure to re-download the inputs when it happens.**"
      ],
      "metadata": {
        "id": "_EOoxrZurmYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Data -- run this cell only one time per runtime\n",
        "!gdown 1fnD0hJ8-_Rngsc-m96ghKtdZAMf0VTjy\n",
        "!unzip \"/content/hill.zip\" -d \"/content/hill\"\n",
        "\n",
        "!gdown 1v2BFVMV0McuD5BstLvDmo1U9MrFAByS5\n",
        "!unzip \"/content/tv.zip\" -d \"/content/tv\"\n"
      ],
      "metadata": {
        "id": "Tspp6CyMroUC",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "YlVZP1tvMAxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Given Helper Functions\n",
        "def apply_homography(H, src):\n",
        "    src_h = np.hstack((src, np.ones((src.shape[0], 1))))\n",
        "    dest =  src_h @ H.T\n",
        "    return (dest / dest[:,[2]])[:,0:2]"
      ],
      "metadata": {
        "id": "y9gRD27_MCDo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############ MY HELPER FUNCTION I - HOMOGRAPHY ##############\n",
        "def calculate_matches(src, tgt, thresh=0.5):\n",
        "  \"\"\"\n",
        "  The function produces the mask of indexes, where desc1 and desc2 are a good match.\n",
        "  The is a modified code from openCV tutotrial.\n",
        "  Inputs:\n",
        "  - src: the sift feature of the source image\n",
        "  - tgt: the sift feature of the target image\n",
        "  - thresh: threshold for Lowe's ratio test\n",
        "  Output:\n",
        "  - The mask of interest\n",
        "  \"\"\"\n",
        "  #Finding NBB using FLANN\n",
        "  FLANN_INDEX_KDTREE = 1\n",
        "  index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "  search_params = dict(checks=50) # or pass empty dictionary\n",
        "\n",
        "  flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
        "  matches = flann.knnMatch(src,tgt,k=2)\n",
        "\n",
        "  #Conducting Lowe's ratio\n",
        "  nbb1 = np.array([[m.queryIdx,m.trainIdx] for (m,n) in matches])\n",
        "  dist = np.array([[m.distance, n.distance] for (m,n) in matches])\n",
        "  ratio = dist[::,0] < thresh*dist[::,1]\n",
        "  answ = nbb1[np.where(ratio==True)[0]]\n",
        "\n",
        "  return answ[::,0], answ[::,1]"
      ],
      "metadata": {
        "id": "OBO9BLc_-EWG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############ MY HELPER FUNCTION II - CROPING ##############\n",
        "def crop_vertical_darkspots(img, y_warp):\n",
        "  \"\"\"\n",
        "  Crop the vertical dark spots of an image resulting from warping\n",
        "  It's assumed that the right image image is warped to match the left one.\n",
        "  It will throw an error when the warped image is bad (eg.it's flipped after warping)\n",
        "  Input:\n",
        "  - img: the warped image\n",
        "  - y_warp: y-position of all four edges of the right image of the panorama after warping\n",
        "            np.array(top_left(y), top_right(y), bottom_left(y), bottom_right(y))\n",
        " Output:\n",
        "  - The desired image\n",
        "  \"\"\"\n",
        "  #___1 == best option, __2 == 2nd best option\n",
        "  max1, max2 = sorted([y_warp[2], y_warp[3]])\n",
        "  if max1 > img.shape[0]:\n",
        "    max1 = img.shape[0]\n",
        "  if max1 <= 0:\n",
        "    max1 = max2 if max2 > 0 and max2 <= img.shape[0] else img.shape[0]\n",
        "\n",
        "  min1, min2 = sorted([y_warp[0], y_warp[1]], reverse=True)\n",
        "  if min1 < 0:\n",
        "    min1 = 0\n",
        "  if min1 >= img.shape[0]:\n",
        "    min1 = min2 if min2 >= 0 and min2 < img.shape[0] else 0\n",
        "\n",
        "  if (max1 <= min1):\n",
        "    min1, max1 = max1, min1\n",
        "\n",
        "  return img[min1:max1, ::, ::]\n",
        "\n",
        "def crop_right_darkspots(img, x_warp):\n",
        "  \"\"\"\n",
        "  Crop the right dark spots of an image resulting from warping\n",
        "  It's assumed that the right image image is warped to match the left one.\n",
        "  It will throw an error when the warped image is bad (eg.it's flipped after warping)\n",
        "  Input:\n",
        "  - img: the warped image\n",
        "  - x_warp: x-position of all four edges of the right image of the panorama after warping\n",
        "                np.array(top_left(x), top_right(x), bottom_left(x), bottom_right(x))\n",
        "  Output:\n",
        "  - The desired image\n",
        "  \"\"\"\n",
        "  #___1 == best option, __2 == 2nd best option\n",
        "  max1, max2 = sorted([x_warp[1], x_warp[3]])\n",
        "  if max1 > img.shape[1]:\n",
        "    max1 = img.shape[1]\n",
        "  if max1 <= 0:\n",
        "    best = max1 if max2 > 0 and max2 <= img.shape[1] else img.shape[1]\n",
        "\n",
        "  return img[::, :max1, ::]"
      ],
      "metadata": {
        "id": "8n5zaErJHckj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############ MY HELPER FUNCTION III - SMOOTHING ##############\n",
        "def pyramidsGL(image, num_levels):\n",
        "  '''\n",
        "  Creates Gaussian (G) and Laplacian (L) pyramids of level \"num_levels\" from image im.\n",
        "  G and L are list where G[i], L[i] stores the i-th level of Gaussian and Laplacian pyramid, respectively.\n",
        "  Input:\n",
        "  - image: The source image\n",
        "  - num_levels: The max level of the pyramid\n",
        "  Output:\n",
        "  - The 2 desired pyramids\n",
        "  \"\"\"\n",
        "  '''\n",
        "  G = [image]\n",
        "  image_a = image\n",
        "  for i in range(num_levels-1):\n",
        "    #blur\n",
        "    image_b = cv2.GaussianBlur(image_a,(21,21),0)\n",
        "    #downsample\n",
        "    image_b = cv2.resize(image_b, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_NEAREST)\n",
        "    #adding\n",
        "    G.append(image_b)\n",
        "    #prep for the next\n",
        "    image_a = image_b\n",
        "  ###########################\n",
        "  L = []\n",
        "  for i in range(0,num_levels-1):\n",
        "    image_a = G[i]\n",
        "    #upscale\n",
        "    ds = image_a.shape\n",
        "    image_b = cv2.resize(G[i+1], (ds[1],ds[0]), interpolation=cv2.INTER_NEAREST)\n",
        "    #blur\n",
        "    image_b = cv2.GaussianBlur(image_b,(21,21),0)\n",
        "    #adding\n",
        "    result = image_a - image_b\n",
        "    L.append(result)\n",
        "  L.append(G[num_levels-1])\n",
        "\n",
        "  return G, L\n",
        "\n",
        "def pyramid_blend(L_l, L_r, G_w):\n",
        "  \"\"\"\n",
        "  It performs a pyramid blending on thhe images on the 2 Laplacian pyramids\n",
        "  with G_w as the weight to determine the ratio to blend the two.\n",
        "  Input:\n",
        "  - L_l: The laplacian pyramid of the left image\n",
        "  - L_r: The laplacian pyramid of the right imgae\n",
        "  - G_w: A gaussian pyramid that serves as a weight.\n",
        "  Output:\n",
        "  - A blended image of the left and right images.\n",
        "  \"\"\"\n",
        "  #Blending\n",
        "  blended = []\n",
        "  for l,r,w in zip(L_l,L_r,G_w):\n",
        "    left = l * w\n",
        "    right = r * (1.0 - w)\n",
        "    blended.append( left + right )\n",
        "  #Reconstruction\n",
        "  img = blended[-1]\n",
        "  for i in range(len(blended)-2,-1,-1):\n",
        "    ds_curr = blended[i].shape\n",
        "    img = cv2.resize(img, (ds_curr[1],ds_curr[0]), interpolation=cv2.INTER_NEAREST)\n",
        "    img = cv2.GaussianBlur(img,(21,21),0)\n",
        "    img = blended[i] + img\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "7IxOdr7zMNuX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############ MY HELPER FUNCTION IV - STITCHING ##############\n",
        "def stitch_images(img1, img2):\n",
        "  \"\"\"\n",
        "  Stitch two images at a time.\n",
        "  Inputs:\n",
        "  - img1, img2 with shape [H, W, 3].\n",
        "  Output:\n",
        "  - stitched_image with shape [H, W, 3].\n",
        "  \"\"\"\n",
        "  #1. Detect keypoints\n",
        "  gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
        "  gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "  sift = cv2.SIFT_create()\n",
        "  kp1, des1 = sift.detectAndCompute(gray1,None)\n",
        "  pts1 = cv2.KeyPoint_convert(kp1)\n",
        "  kp2, des2 = sift.detectAndCompute(gray2,None)\n",
        "  pts2 = cv2.KeyPoint_convert(kp2)\n",
        "\n",
        "  #2. Match keypoints\n",
        "  if des1 is None or des2 is None:\n",
        "    raise Exception('No similarities found between the 2 images. Please try again.')\n",
        "  src_mask, tgt_mask = calculate_matches(des1,des2)\n",
        "  pts1_matches = pts1[src_mask]\n",
        "  pts2_matches = pts2[tgt_mask]\n",
        "\n",
        "  #3. Estimate homography with matched keypoints (using RANSAC)\n",
        "    #I originally have to find it by myself, but I omit the code to prevent plagirism.\n",
        "  H,_ = cv2.findHomography(pts1_matches, pts2_matches, cv2.RANSAC, 5.0)\n",
        "\n",
        "  #4. Combine images\n",
        "    #image adjustments\n",
        "  ds1 = img1.shape\n",
        "  ds2 = img2.shape\n",
        "  img_r = cv2.warpPerspective(img2, H, dsize=(ds1[1]+ds2[1],ds1[0]),\\\n",
        "                              flags=cv2.WARP_INVERSE_MAP).astype(np.float64)\n",
        "  edges = np.array([ [0,0],[ds2[1],0],[0,ds2[0]],[ds2[1],ds2[0]] ])\n",
        "  edges_warp = apply_homography(np.linalg.inv(H), edges)\n",
        "  #edges = np.array(top_left(x,y), top_right(x,y), bottom_left(x,y), bottom_right(x,y))\n",
        "  x_warp, y_warp = edges_warp[::,0].astype(np.int64), edges_warp[::,1].astype(np.int64)\n",
        "  img_r = crop_right_darkspots(img_r, x_warp)\n",
        "\n",
        "  ds_r = img_r.shape\n",
        "  if (ds_r[1] <= ds1[1]):\n",
        "    raise Exception('The homography matrix is bad. Please try again.')\n",
        "  img_l = np.append(img1, np.zeros((ds_r[0],ds_r[1]-ds1[1],3)), 1)\n",
        "\n",
        "    #blend & combine\n",
        "  weight = np.zeros(ds_r)\n",
        "  ovlp_start_x = x_warp[0] if x_warp[0] < x_warp[2] else x_warp[2]\n",
        "  weight[::,:ovlp_start_x+(ds1[1]-ovlp_start_x)//2] = 1\n",
        "\n",
        "  max_level = int( np.floor(np.log2( min(ds_r[0],ds_r[1]) )) )\n",
        "  _, L_r = pyramidsGL(img_r, max_level)\n",
        "  _, L_l = pyramidsGL(img_l, max_level)\n",
        "  G_w,_ = pyramidsGL(weight, max_level)\n",
        "\n",
        "  fin = crop_vertical_darkspots(pyramid_blend(L_l,L_r,G_w), y_warp)\n",
        "\n",
        "  return cv2.convertScaleAbs(fin)"
      ],
      "metadata": {
        "id": "zx78_07RHeyN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Function"
      ],
      "metadata": {
        "id": "kLyTTTL0NVZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting User Input\n",
        "print('A python implementation of image stitching =)')\n",
        "print('WARNING: MAKE SURE THAT ONLY RELEVANT IMAGES ARE IN THE FOLDER!')\n",
        "print('         ALSO, ENSURE THE IMAGE FILE EXTENSION IS UNIFORM\\n')\n",
        "img_path = input('Enter File Path(eg. /content/hill/*.JPG): ')\n",
        "fin_name = input('Under What Name Would You Like the Result to be Saved?(eg. result.jpg) ')\n",
        "\n",
        "#Processing the Inputs\n",
        "img_list = sorted(glob.glob(img_path))\n",
        "if len(img_list) == 0:\n",
        "  raise FileNotFoundError('No Images is Found in the Given Folder')\n",
        "fin_ext = os.path.splitext(fin_name)[-1].lower()\n",
        "if fin_ext!='.jpg' and fin_ext!='.jpeg' and fin_ext!='.png' and fin_ext!='.gif':\n",
        "  raise SyntaxWarning('The File Extension for the Resulting Image Doesn\\'t look right.')\n",
        "\n",
        "print('\\nImages Found: ', img_list)\n",
        "print('\\nProcessing....')\n",
        "panorama = cv2.imread(img_list[0])\n",
        "panorama = cv2.cvtColor(panorama, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "for i in range(1,len(img_list)):\n",
        "  next_img = cv2.imread(img_list[i])\n",
        "  next_img = cv2.cvtColor(next_img, cv2.COLOR_BGR2RGB)\n",
        "  panorama = stitch_images(panorama, next_img)\n",
        "\n",
        "#Previewing & Saving\n",
        "print('\\nAlmost Done!')\n",
        "plt.imshow(panorama)\n",
        "plt.title('Preview')\n",
        "plt.show()\n",
        "plt.imsave(fin_name, panorama)"
      ],
      "metadata": {
        "id": "0sWxf-3WQomQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}